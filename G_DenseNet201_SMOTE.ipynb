{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"T16aRmnONPYi"},"outputs":[],"source":["from google.colab import drive \n","drive.mount('/content/drive')\n"]},{"cell_type":"markdown","metadata":{"id":"8wGRA1oeKgxS"},"source":["## Imports"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dNyLQOcIXCQi"},"outputs":[],"source":["import tensorflow\n","import tensorflow as tf\n","from tensorflow import keras\n","from keras import utils\n","from tensorflow.keras.utils import plot_model,to_categorical\n","from tensorflow.keras.optimizers import Adam,SGD\n","from keras.models import Model,Sequential,load_model,model_from_json\n","from keras.layers import GlobalAveragePooling2D, Dense, BatchNormalization\n","from keras.losses import CategoricalCrossentropy\n","from tensorflow.keras.applications import (DenseNet121, DenseNet169, DenseNet201, \n","      InceptionResNetV2, InceptionV3, MobileNet, MobileNetV2, ResNet101, ResNet152, ResNet50, ResNet50V2, VGG16, VGG19, Xception)\n","from sklearn import metrics\n","from keras.metrics import ( TrueNegatives,TruePositives, FalseNegatives, FalsePositives, AUC, Precision, Recall)\n","from sklearn.metrics import (classification_report, confusion_matrix, average_precision_score,\n","    precision_recall_curve, roc_auc_score, roc_curve, f1_score)\n","from sklearn.utils import class_weight\n","from sklearn import preprocessing\n","from tensorflow.python.client import device_lib\n","import cv2\n","from IPython.display import display\n","from PIL import Image\n","import seaborn as sns\n","from  matplotlib import pyplot as plt\n","import matplotlib.image as mpimg\n","from tqdm import tqdm_notebook as tq \n","%matplotlib inline\n","import imutils\n","from imutils import paths\n","from tqdm import tqdm_notebook\n","import sklearn.metrics as metrics\n","import pandas as pd\n","import math  \n","import os\n","import numpy as np                                                                                                                                                                                                                                                                                                                                    \n","import seaborn\n","import timeit"]},{"cell_type":"markdown","metadata":{"id":"IGuDcopmNzAg"},"source":["## **Loading Image**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Oyp_5HX2pngv"},"outputs":[],"source":["img_folder='/content/drive/MyDrive/Covid-19/New Run/Data/Radio/train'\n","img_test = '/content/drive/MyDrive/Covid-19/New Run/Data/Radio/test'\n","img_valid = '/content/drive/MyDrive/Covid-19/New Run/Data/Radio/valid'\n","IMG_WIDTH=224\n","IMG_HEIGHT=224"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"z0zhZIhlxKnx"},"outputs":[],"source":["def Norm (pixels):\n","  # calculate global mean and standard deviation\n","  mean, std = pixels.mean(), pixels.std()\n","  # global standardization of pixels\n","  pixels = (pixels - mean) / std\n","  # confirm it had the desired effect\n","  return pixels\n","\n","def create_dataset(img_folder):\n","   \n","    img_data_array=[]\n","    class_name=[]\n","   \n","    for dir1 in os.listdir(img_folder):\n","        for file in tq(os.listdir(os.path.join(img_folder, dir1))):\n","            image_path= os.path.join(img_folder, dir1,  file)\n","            image= cv2.imread(image_path)\n","            if len(image.shape)<3:\n","              image= cv2.cvtColor(image,cv2.COLOR_GRAY2RGB)\n","              image=cv2.resize(image, (IMG_HEIGHT, IMG_WIDTH),interpolation = cv2.INTER_AREA)\n","              image=np.array(image)\n","              image = image.astype('float32')\n","              image = Norm(image)\n","              img_data_array.append(image)\n","              class_name.append(dir1)\n","            else:\n","              image=cv2.resize(image, (IMG_HEIGHT, IMG_WIDTH),interpolation = cv2.INTER_AREA)\n","              image=np.array(image)\n","              image = image.astype('float32')\n","              image = Norm(image)\n","              img_data_array.append(image)\n","              class_name.append(dir1)\n","    return img_data_array, class_name\n","    \n","def data_aug (img_data, class_name):\n","  M = np.float32([[1,0,15],[0,1,15]])\n","  for i in range(len(img_data)):\n","    img = img_data[i]\n","    rows,cols,c = img.shape\n","    dst = cv2.warpAffine(img,M,(cols,rows))\n","    rot =  imutils.rotate(img, -10)\n","    img_data.append(dst)\n","    class_name.append(class_name[i])\n","    img_data.append(rot)\n","    class_name.append(class_name[i])\n","  return img_data, class_name\n","\n","def data_prepro(img_data):\n","  image_data_pre=[]\n","  for i in range(len(img_data)):\n","    img = img_data[i]\n","    lab= cv2.cvtColor(img, cv2.COLOR_BGR2LAB)\n","    l, a, b = cv2.split(lab)\n","    clahe = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(8,8))\n","    cl = clahe.apply(l)\n","    cl = cv2.cvtColor(cl, cv2.COLOR_BGR2RGB)\n","    image_data_pre.append(cl)\n","  return img_data_pre"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Z5M3Vd0aqd0_"},"outputs":[],"source":["img_data, class_name =create_dataset(img_folder)\n","img_data1, class_name1 = data_aug (img_data, class_name)\n","target_dict={k: v for v, k in enumerate(np.unique(class_name1))}\n","target_dict\n","target_val=  [target_dict[class_name1[i]] for i in range(len(class_name1))]\n","trainX =np.array(img_data1, np.float32)\n","trainY = np.array(list(map(int,target_val)), np.float32)\n","print(trainX.shape)\n","print(trainY.shape)"]},{"cell_type":"code","source":["%pylab inline\n","import matplotlib.pyplot as plt\n","import matplotlib.image as mpimg\n","# img = mpimg.imread()\n","imgplot = plt.imshow(trainX[50])\n","plt.show()"],"metadata":{"id":"s5Krm-ws1zrR"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nS0MhEYz_ZWh"},"outputs":[],"source":["img_test_data1, class_test_name1 =create_dataset(img_test)\n","target_test_dict={k: v for v, k in enumerate(np.unique(class_test_name1))}\n","target_test_val=  [target_test_dict[class_test_name1[i]] for i in range(len(class_test_name1))]\n","testX =np.array(img_test_data1, np.float32)\n","testY = np.array(list(map(int,target_test_val)), np.float32)\n","print(testX.shape)\n","print(testY.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"THEOTqlCgjV8"},"outputs":[],"source":["img_valid_data1, class_valid_name1 =create_dataset(img_valid)\n","target_valid_dict={k: v for v, k in enumerate(np.unique(class_valid_name1))}\n","target_valid_val=  [target_valid_dict[class_valid_name1[i]] for i in range(len(class_valid_name1))]\n","validX =np.array(img_valid_data1, np.float32)\n","validY = np.array(list(map(int,target_valid_val)), np.float32)\n","print(validX.shape)\n","print(validY.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rRx4IjYJBtiA"},"outputs":[],"source":["%pylab inline\n","# img = mpimg.imread()\n","imgplot = plt.imshow(trainX[800])\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1OOpILTwUquM"},"outputs":[],"source":["labels=['COVID','NORMAL','Viral Pneumonia']\n","train_Y = to_categorical(trainY,3)\n","valid_Y = to_categorical(validY,3)\n","plt.xticks(rotation=90)\n","plt.bar(x=labels, height=np.mean(train_Y, axis=0))\n","plt.title(\"Frequency of Each Class\")\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zh5mMIV8Sl6K"},"outputs":[],"source":["def compute_class_freqs(labels):\n","    \"\"\"\n","    Compute positive and negative frequences for each class.\n","\n","    Args:\n","        labels (np.array): matrix of labels, size (num_examples, num_classes)\n","    Returns:\n","        positive_frequencies (np.array): array of positive frequences for each\n","                                         class, size (num_classes)\n","        negative_frequencies (np.array): array of negative frequences for each\n","                                         class, size (num_classes)\n","    \"\"\"\n","    # total number of patients (rows)\n","    N = labels.shape[0]\n","    \n","    positive_frequencies = np.sum(labels == 0,axis=0) / N\n","    negative_frequencies = np.sum(labels == 1,axis=0) / N\n","    return positive_frequencies, negative_frequencies"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Zsvzx0HAYRPi"},"outputs":[],"source":["freq_pos, freq_neg = compute_class_freqs(train_Y)\n","freq_pos\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NNypGcfcYVEJ"},"outputs":[],"source":["data = pd.DataFrame({\"Class\": labels, \"Label\": \"Positive\", \"Value\": freq_pos})\n","data = data.append([{\"Class\": labels[l], \"Label\": \"Negative\", \"Value\": v} for l,v in enumerate(freq_neg)], ignore_index=True)\n","plt.xticks(rotation=90)\n","f = sns.barplot(x=\"Class\", y=\"Value\", hue=\"Label\" ,data=data)"]},{"cell_type":"code","source":["# Import and Initialize\n","from imblearn.over_sampling import SMOTE\n","sm = SMOTE(random_state=42)\n","# Flatten/Reshape Image Data to 1D Vector\n","X = np.reshape(trainX,(trainX.shape[0], trainX.shape[1] * trainX.shape[2] *trainX.shape[3]))\n","\n","# Apply SMOTE\n","X_smote, y_smote = sm.fit_resample(X, trainY)\n","\n","# Reshape upsampled data into original form for DNN model\n","X_train = X_smote.reshape(X_smote.shape[0], IMG_WIDTH, IMG_HEIGHT, 3) \n","\n","from tensorflow.keras.utils import to_categorical\n","y_smote1 = to_categorical(y_smote)\n","plt.xticks(rotation=90)\n","plt.bar(x=labels, height=np.mean(y_smote, axis=0))\n","plt.title(\"Frequency of Each Class\")\n","plt.show()\n","print(\"Before SMOTE, counts of label '0':{} \".format(sum(trainY ==0)))\n","print(\"Before SMOTE, counts of label '1':{}\".format(sum(trainY ==1)))\n","print(\"Before SMOTE, counts of label '2':{}\\n\".format(sum(trainY ==2)))\n","print(\"*****************************************************************\")\n","print(\"After SMOTE, counts of label '0':{} \".format(sum(y_smote ==0)))\n","print(\"After SMOTE, counts of label '1':{}\".format(sum(y_smote ==1)))\n","print(\"After SMOTE, counts of label '2':{}\\n\".format(sum(y_smote ==2)))"],"metadata":{"id":"yG_jWpeCUvh_"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"dPhXmBRS1db-"},"source":["## **Trainig --DenseNet201**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8A7izFp1zfft"},"outputs":[],"source":["start = timeit.default_timer()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DoI4buuSMegW"},"outputs":[],"source":["model_name = 'DenseNet201_D1_WithDA'\n","# create the base pre-trained model\n","base_model=tf.keras.applications.DenseNet201(weights='imagenet', include_top=False)\n","x = base_model.output\n","# add a global spatial average pooling layer\n","x = GlobalAveragePooling2D()(x)\n","# and a logistic layer\n","predictions = Dense(3, activation=\"softmax\")(x)\n","model = Model(inputs=base_model.input, outputs=predictions)\n","model.compile(optimizer=Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8hG-cVNwMoDS"},"outputs":[],"source":["y_smote1 = to_categorical(y_smote)\n","hist= model.fit(X_train, y_smote1, epochs=20, batch_size=8, validation_data= (validX, valid_Y), shuffle = True, verbose=1)\n","hist_df = pd.DataFrame(hist.history) "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ydSCyI-ozrPz"},"outputs":[],"source":["\n","stop = timeit.default_timer()\n","execution_time = stop - start\n","print(\"The model was trained in \"+str(execution_time)) # It returns time in seconds\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fu-5C-j-yzi8"},"outputs":[],"source":["hist_df = pd.DataFrame(hist.history) \n","hist_csv_file = '/content/drive/MyDrive/Covid-19/New Run/SMOTE/History/'+model_name+'.csv'\n","\n","with open(hist_csv_file, mode='w') as f:\n","    hist_df.to_csv(f)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2us_Yt3IM2L4"},"outputs":[],"source":["\n","plt.subplot(2,1,1)\n","plt.plot(hist.history['accuracy'])\n","plt.plot(hist.history['val_accuracy'])\n","plt.title('model accuracy')\n","plt.ylabel('Accuracy')\n","plt.xlabel('epoch')\n","plt.legend(['train', 'val'], loc='upper left')\n","plt.savefig('/content/drive/MyDrive/Covid-19/New Run/SMOTE/Accuracy/'+model_name+'.png', bbox_inches='tight', dpi=300)\n","plt.show()\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"f3NByzH0FGHQ"},"outputs":[],"source":["plt.subplot(2,1,2)\n","plt.plot(hist.history['loss'])\n","plt.plot(hist.history['val_loss'])\n","plt.ylabel('Loss')\n","plt.xlabel('epoch')\n","plt.legend(['train', 'loss'], loc='upper left')\n","plt.savefig('/content/drive/MyDrive/Covid-19/New Run/SMOTE/Loss/'+model_name+'.png', bbox_inches='tight', dpi=300)\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ex9HP9lHOUwC"},"outputs":[],"source":["labels = ['COVID-19',\n","          'NORMAL', \n","          'Viral Pneumonia'\n","      ]\n","predicted_vals = model.predict(testX, steps = testX.shape[0])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wgEwClZlM5Og"},"outputs":[],"source":["predicted_vals = np.argmax(predicted_vals, axis=1)\n","cm = confusion_matrix(testY, predicted_vals)\n","def plot_confusion_matrix(data, labels, output_filename):\n","    \"\"\"Plot confusion matrix using heatmap.\n"," \n","    Args:\n","        data (list of list): List of lists with confusion matrix data.\n","        labels (list): Labels which will be plotted across x and y axis.\n","        output_filename (str): Path to output file.\n"," \n","    \"\"\"\n","    plt.title(\"Confusion Matrix\")\n"," \n","    seaborn.set(font_scale=0.5)\n","    ax = seaborn.heatmap(data, annot=True, fmt=\"d\", cmap=\"YlGnBu\", cbar_kws={'label': 'Scale'})\n"," \n","    ax.set_xticklabels(labels)\n","    ax.set_yticklabels(labels)\n"," \n","    ax.set(ylabel=\"True Label\", xlabel=\"Predicted Label\")\n","    plt.savefig(output_filename, bbox_inches='tight', dpi=300)\n","    seaborn.set(color_codes=True)\n","    plt.figure(1, figsize=(9, 6))\n","\n","plot_confusion_matrix(cm,labels,'/content/drive/MyDrive/Covid-19/New Run/SMOTE/Confusion Matrix/'+model_name+'.png')\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DaMTwSheNGe5"},"outputs":[],"source":["# To plot a ROC curve and AUC score for multi-class classification:\n","# set plot figure size\n","fig, c_ax = plt.subplots(1,1, figsize = (12, 8))\n","\n","def multiclass_roc_auc_score(y_test, y_pred, average=\"macro\"):\n","    lb = preprocessing.LabelBinarizer()\n","    lb.fit(y_test)\n","    y_test = lb.transform(y_test)\n","    y_pred = lb.transform(y_pred)\n","\n","    for (idx, c_label) in enumerate(labels): # all_labels: no of the labels, for ex. ['cat', 'dog', 'rat']\n","        fpr, tpr, thresholds = metrics.roc_curve(y_test[:,idx].astype(int), y_pred[:,idx])\n","        c_ax.plot(fpr, tpr, label = '%s (AUC:%0.2f)'  % (c_label, metrics.auc(fpr, tpr)))\n","    c_ax.plot(fpr, fpr, 'b-', label = 'Random Guessing')\n","    return metrics.roc_auc_score(y_test, y_pred, average=average)\n","\n","# calling\n","# test_generator.reset() # resetting generator\n","multiclass_roc_auc_score(testY, predicted_vals)"]},{"cell_type":"markdown","metadata":{"id":"hhpsYHUmKS-T"},"source":["## **Evaluation metrics**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Tx4hO91GM_Qh"},"outputs":[],"source":["get_performance_metrics(test_y,preds_t, labels, acc=get_accuracy, prevalence=get_prevalence, sens=get_sensitivity, spec=get_specificity, ppv=get_ppv, npv=get_npv, auc=roc_auc_score,f1=f1_score)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zcqnBhsTNCrQ"},"outputs":[],"source":["model_json = model.to_json()\n","with open('/content/drive/MyDrive/Covid-19/New Run/SMOTE/Model/'+ model_name + '.json', \"w\") as json_file:\n","    json_file.write(model_json)\n","model.save_weights('/content/drive/MyDrive/Covid-19/New Run/SMOTE/Model/'+ model_name + '.h5')\n","print(\"Saved model to disk\")\n","\n","# load json and create model\n","json_file = open('/content/drive/MyDrive/Covid-19/New Run/SMOTE/Model/'+ model_name + '.json', 'r')\n","loaded_model_json = json_file.read()\n","json_file.close()\n","loaded_model = model_from_json(loaded_model_json)\n","# load weights into new model\n","loaded_model.load_weights('/content/drive/MyDrive/Covid-19/New Run/SMOTE/Model/'+ model_name +'.h5')\n","print(\"Loaded model from disk\")\n","config = model.get_config()\n","new_model = keras.Model.from_config(config)\n"]}],"metadata":{"accelerator":"GPU","colab":{"background_execution":"on","collapsed_sections":["8wGRA1oeKgxS","IGuDcopmNzAg"],"machine_shape":"hm","name":"G_DenseNet201_SMOTE.ipynb","provenance":[],"authorship_tag":"ABX9TyOuRG1YJ4EZwtkASFRijgHQ"},"kernelspec":{"display_name":"Python 3","name":"python3"}},"nbformat":4,"nbformat_minor":0}